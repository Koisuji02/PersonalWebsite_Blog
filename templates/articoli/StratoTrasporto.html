{% extends "single.html" %}
{% block articolo %}
<div class="testo-articolo">
    <p>Questo strato risolve dei problemi legati al trasporto (<span class="text-primary">MULTIPLEXING</span> = poter distinguere messaggi di app diverse anche se hanno tutte la stessa destinazione IP; <span class="text-primary">DEMULTIPLEXING</span> = arrivato un messaggio, devo capire per quale applicazione è), alla sicurezza e alle non-garanzie dell’IP (<mark>l’IP non offre garanzie</mark>, quindi se perdo un pacchetto devo rifare tutto → perciò all’edge dovrò implementare un sistema per “reliable data transfer”, ovvero dovrò implementare dei protocolli a finestra [dunque leggera perdita di prestazioni, ma al tempo stesso garanzie; quindi questo va bene nella rete Internet]). Altro servizio offerto è il controllo di flusso (evita il sovraccarico della destinazione [es. server di ultima generazione che comunica con un sensorino non deve mandare al sensorino dati alla massima velocità in quanto è inutile]) e il controllo di congestione (evita il sovraccarico della rete). UDP offre il servizio obbligatorio, ovvero solo multiplexing e demultiplexing [connectionless]; mentre TCP offre anche i servizi facoltativi (reliable data transfer, controllo di flusso e controllo di congestione) [connection-oriented]. Ricorda che lo <mark>strato4 è all’edge</mark> (ovvero host, server, client e NON al router → il router non ha strato4).</p>
    <p>Quindi questo livello trasporto crea un canale logico tra 2 processi applicativi in esecuzione sugli host (end-system, edges); come abbiamo detto prima, UDP non è affidabile (non protocollo a finestra), mentre TCP sì. Entrambi però non offrono garanzie di banda e garanzie di ritardo.</p>
    <p class="mb-1">Si usano le porte per il DEMULTIPLEXING, ovvero per reindirizzare il segmento all’applicazione corretta:</p>
    <ul>
        <li><strong class="text-primary">CONNECTIONLESS DEMULTIPLEXING</strong> [UDP] → UDP socket identificato da IP destinazione e numero di porta; quando un host riceve un segmento UDP, controlla la porta di destinazione e manda il segmento UDP a quella porta (il processo che riceve deve “ascoltare” quella porta [socket API]);</li>
        <li><strong class="text-primary">CONNECTION-ORIENTED DEMULTIPLEXING</strong> [TCP] → socket TCP identificato da indirizzo IP sorgente, porta sorgente, indirizzo IP destinazione, porta destinazione (perché magari la comunicazione con un host è più veloce di un’altra rispetto ad un altro host, quindi serve identificarli); ogni processo associato ad 1 solo socket (oppure a più socket se associamo ad ogni socket un thread del processo).</li>
    </ul>
    <p><mark>Come fa un client a sapere il numero di porta giusto da contattare?</mark> Si usano le “WELL-KNOWN PORTS”, ovvero le porte da 0 a 1024, ognuna associata ad una particolare applicazione (es. http usa il protocollo TCP sulla porta 80). Posso anche non usare questo standard (ovvero usare porte randomiche), ma questo crea un problema ai client (i quali pensano di comunicare con la porta standard).</p>
    <div class="row">
        <p class="col-8 col-lg-9">Come funziona l’<strong class="text-primary">UDP</strong> (User Datagram Protocol)? Come abbiamo già detto è un servizio connectionless (no handshaking tra sorgente e destinazione UDP; ogni segmento trattato indipendemente dagli altri) che offre solo multiplexing e demultiplexing, che non offre affidabilità, ma offre alte prestazioni (infatti viene usato nello streaming multimediale [loss tolerant], nel DNS [c’è solo 1 domanda e 1 risposta, quindi non mi serve il protocollo a finestra]). Oltre a ciò, nell’UDP segment header troviamo anche un campo “CHECKSUM”, ovvero UDP fa anche “error detection” (non correction, quindi se pacchetto sbagliato, lo scarto e non lo correggo).</p>
        <img class="img-fluid col-4 col-lg-3" src="{{url_for('static', filename='UDP.png')}}" alt="UDPs">
    </div>
    <p>Nel protocollo <strong class="text-primary">TCP</strong> possiamo implementare i protocolli a finestra (noi abbiamo visto Go-Back-N [cumulative ack e 1 timeout] e Selective Repeat [individual ack per ogni pacchetto e 1 timeout per ogni pacchetto ancora non confermato]). <mark>Come funziona TCP?</mark> È punto-punto (1 sorgente e 1 destinazione) [infatti per trasmissioni multicast devo usare per forza UDP]; è affidabile, “byte-stream”, con un approccio “pipeline” (finestra di trasmissione, usata per aumentare/ridurre il bitrate, ovvero per il controllo di congestione e di flusso), “full-duplex” (ovvero si possono mandare dati in maniera bidirezionale nella stessa connessione), “connection-oriented” (handshaking tra sorgente e destinazione).</p>
    <p class="mb-1">⚠️Nel “TCP segment format”, ci sono anche i flag (A = Ack number valid, R = Reset connection, S e F = aprire e chiudere la connessione), la receive window (per il controllo di flusso), il checksum (error detection), il “sequence number” (valore del 1° byte, riferito all’intero stream di bytes) e “acknowledgement number” (numero che mi aspetto dal prossimo byte) [questo perché TCP usa l’ACK cumulativo, ma la gestione fuori sequenza dipende dall’implementazione [≠ Go-Back-N]].</p>
    <p class="mb-1">Per quanto riguarda l’<strong>AFFIDABILITÁ</strong> (ignorando inzialmente il problema degli ACK duplicati e del controllo di flusso e congestione), vediamo come funziona TCP. Vengono ricevuti dati dall’applicazione: si crea un segmento con un certo numero di sequenza (numero del 1° byte nel segmento) e fa partire il timer (se non è già attivo) [timer riferito al più vecchio segmento non ancora confermato (unacked)]; quando scade il timeout, invio solo il segmento che ha causato il timeout (non invio di nuovo tutta la finestra, quindi diverso dal Go-Back-N [quindi se si perdono molti pacchetti, si preferisce Go-Back-N, ma quindi non se ne perdono troppi se usiamo questo procedimento nel TCP (lo vedremo nel controllo di congestione e lo vediamo anche perché tutti i sistemi operativi hanno una finestra di ricezione > 1)]) e faccio ripartire il timer. Quando riceve l’ACK, si starta un timer se ci sono ancora segmenti non confermati.</p>
    <p>Vediamo degli scenari particolari di ritrasmissione (ACK in ritardo vengono comunque presi dall’Host A!!!):</p>
    <div class="row mb-3">
        <div class="col-1"></div>
        <img class="img-fluid col-10" src="{{url_for('static', filename='TCP1.png')}}" alt="TCP1">
        <div class="col-1"></div>
    </div>
    <p class="mb-1">Infatti situazione particolari sono:</p>
    <ul class="mb-1">
        <li>Pacchetti in arrivo con numero di sequenza atteso n con tutti i pacchetti fino ad n già confermati (acked) → si usa “delayed ACK” (si aspetta per 500ms per il prossimo segmento e se non arriva si manda l’ACK);</li>
        <li>Pacchetti in arrivo con numero di sequenza atteso n con 1 pacchetto non ancora confermato (ack pending) → si manda 1 singolo ACK cumulativo;</li>
        <li>Pacchetto fuori sequenza in arrivo (con numero di sequenza maggiore di quello atteso [gap detected]) → si manda un ACK duplicato (indicante il numero di sequenza atteso del prossimo byte);</li>
        <li>Pacchetto in arrivo che mi completa il gap → mando un ACK.</li>
    </ul>
    <p>Questi ACK duplicati si possono usare per il <span class="text-primary">TCP FAST RETRANSMIT</span>, ovvero, dopo aver ricevuto 3 ack con lo stesso numero (per lo stesso pacchetto) [ovvero 3 ACK duplicati], il trasmettitore ritrasmette il pacchetto cercato, prima che scada  il timeout (ovvero a furia di chiedere, verrà mandato il pacchetto).</p>
    <p class="mb-1">Per quanto riguarda il <strong class="text-primary">CONTROLLO DI FLUSSO</strong> (il ricevitore controlla il trasmettitore, così da non generare sovraccarico sul ricevitore), il ricevitore manda al trasmettitore la dimensione del “free buffer space” [rwnd → receive window dimension] dentro il RcvBuffer (c’è un campo “receive window”  apposito nel TCP message) e il trasmettitore si regola di conseguenza [twnd≤rwnd].</p>
    <p>Prima di scambiarsi dati, il ricevitore e il trasmettitore fanno “TCP 3-way handshake” (ovvero decidono come instaurare la connessione e cosa vogliono ottenere dalla connessione), ovvero aprono la connessione TCP. Invece per chiudere la connessione TCP, sia client sia server mandano un TCP segment con il bit di FIN = 1 e rispondono reciprocamente con l’ACK.</p>
    <p class="mb-1">Per quanto riguarda il <strong class="text-primary">CONTROLLO DI CONGESTIONE</strong> (congestione = traffico sulla rete a causa di sorgenti che mandano dati troppo velocemente in rete, per cui si perdono pacchetti e si generano ritardi), ci sono 2 modi per risolvere:</p>
    <ul class="mb-2">
        <li>NETWORK-ASSISTED CONGESTION CONTROL → router mandano dei segnali alle sorgenti per dire che si sta generando troppo traffico. Questo però complica i router, noi vogliamo invece avere i router “semplici” e gli edge (ovvero i terminali) più complessi [perciò TCP usa l’altro metodo];</li>
        <li>END-END CONGESTION CONTROL → controllo affidato agli edges (terminali, end-systems).</li>
    </ul>
    <p class="mb-1">Il controllo di congestione TCP viene fatto usando il modello della cwnd (congestion window dimension, ovvero un buffer “fittizio” che mi indica quanto traffico c’è sulla rete) [twnd≤min{rwnd,cwnd}]; proprio pechè la cwnd è fittizia, devo poterla stimare e lo faccio basandomi sul trasmettitore; ci sono diversi algoritmi:</p>
    <ul>
        <li><span class="text-primary">AIMD</span> o CA (addictive increase multiplicative decrease o congestion avoidance) → applicato durante la fase di congestion avoidance: mi avvicino linearmente al limite della cwnd, incrementando la cwnd di 1 MSS (maximum segment size) ogni RTT [additive increase]; quando si perde un pacchetto (scade timeout o ACK duplicato), si dimezza la cwnd;</li>
        <li><span class="text-primary">SLOW START</span> → all’inizio cwnd = 1 MSS, ma poi raddoppio la cwnd ogni RTT (crescita esponenziale, la si ottiene incrementando la cwnd di 1 MSS ogni ACK ricevuto e non ogni RTT); quindi inizialmente lento, ma la crescita esponenziale lo velocizza.</li>
    </ul>
    <p class="mb-1">⚠️La perdita di un pacchetto è segnata da un timeout che scade o da ACK duplicati; il timeout però è peggio. In TCP-Reno cosa succede in conseguenza a questi eventi?</p>
    <ul class="livello2 mb-1">
        <li>Perdita di pacchetto da timeout → cwnd settata ad 1 MSS e la finestra cresce prima esponenzialmente fino al threshold (per poi crescere linearmente);</li>
        <li>Perdita di pacchetto da 3 ACK duplicati → cwnd dimezzata e poi cresce linearmente.</li>
    </ul>
    <p>Quindi quando bisogna passare dal SLOW START (esponenziale) all’AIMD (o CA)? Quando cwnd arriva alla metà del suo valore prima del timeoout (usiamo la variabile ssthresh posta ad ½ della cwnd appena prima della perdita di un pacchetto).</p>
    <p>⚠️TCP è “fair”, ovvero, se tutte le sue sessioni condividono lo stesso “bottleneck”, ognuna dovrebbe avere lo stesso rate (se la banda c’è TCP gliela lascia)!</p>
</div>
{% endblock %}